{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"..\\employee_survey.csv\")\n",
    "# data3 = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmpID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Dept</th>\n",
       "      <th>EmpType</th>\n",
       "      <th>WLB</th>\n",
       "      <th>WorkEnv</th>\n",
       "      <th>...</th>\n",
       "      <th>SleepHours</th>\n",
       "      <th>CommuteMode</th>\n",
       "      <th>CommuteDistance</th>\n",
       "      <th>NumCompanies</th>\n",
       "      <th>TeamSize</th>\n",
       "      <th>NumReports</th>\n",
       "      <th>EduLevel</th>\n",
       "      <th>haveOT</th>\n",
       "      <th>TrainingHoursPerYear</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>Married</td>\n",
       "      <td>Mid</td>\n",
       "      <td>7</td>\n",
       "      <td>IT</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Car</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>True</td>\n",
       "      <td>33.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>Married</td>\n",
       "      <td>Mid</td>\n",
       "      <td>12</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Car</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>Single</td>\n",
       "      <td>Intern/Fresher</td>\n",
       "      <td>1</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>True</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>Married</td>\n",
       "      <td>Junior</td>\n",
       "      <td>6</td>\n",
       "      <td>IT</td>\n",
       "      <td>Contract</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>True</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Other</td>\n",
       "      <td>23</td>\n",
       "      <td>Single</td>\n",
       "      <td>Junior</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Part-Time</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Car</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>False</td>\n",
       "      <td>20.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmpID  Gender  Age MaritalStatus        JobLevel  Experience       Dept  \\\n",
       "0      6    Male   32       Married             Mid           7         IT   \n",
       "1     11  Female   34       Married             Mid          12    Finance   \n",
       "2     33  Female   23        Single  Intern/Fresher           1  Marketing   \n",
       "3     20  Female   29       Married          Junior           6         IT   \n",
       "4     28   Other   23        Single          Junior           1      Sales   \n",
       "\n",
       "     EmpType  WLB  WorkEnv  ...  SleepHours       CommuteMode  \\\n",
       "0  Full-Time    1        1  ...         7.6               Car   \n",
       "1  Full-Time    1        1  ...         7.9               Car   \n",
       "2  Full-Time    2        4  ...         6.5         Motorbike   \n",
       "3   Contract    2        2  ...         7.5  Public Transport   \n",
       "4  Part-Time    3        1  ...         4.9               Car   \n",
       "\n",
       "   CommuteDistance  NumCompanies TeamSize  NumReports  EduLevel  haveOT  \\\n",
       "0               20             3       12           0  Bachelor    True   \n",
       "1               15             4       11           0  Bachelor   False   \n",
       "2               17             0       30           0  Bachelor    True   \n",
       "3               13             2        9           0  Bachelor    True   \n",
       "4               20             0        7           0  Bachelor   False   \n",
       "\n",
       "   TrainingHoursPerYear JobSatisfaction  \n",
       "0                  33.5               5  \n",
       "1                  36.0               5  \n",
       "2                  10.5               5  \n",
       "3                  23.0               5  \n",
       "4                  20.5               5  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Prep\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "['Male' 'Female' 'Other']\n",
      "MaritalStatus\n",
      "['Married' 'Single' 'Divorced' 'Widowed']\n",
      "JobLevel\n",
      "['Mid' 'Intern/Fresher' 'Junior' 'Senior' 'Lead']\n",
      "Dept\n",
      "['IT' 'Finance' 'Marketing' 'Sales' 'Operations' 'Customer Service'\n",
      " 'Legal' 'HR']\n",
      "EmpType\n",
      "['Full-Time' 'Contract' 'Part-Time']\n",
      "CommuteMode\n",
      "['Car' 'Motorbike' 'Public Transport' 'Bike' 'Walk']\n",
      "EduLevel\n",
      "['Bachelor' 'High School' 'Master' 'PhD']\n"
     ]
    }
   ],
   "source": [
    "cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "for col in cols:\n",
    "    print(col)\n",
    "    print(data[col].unique())\n",
    "\n",
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    res = res.drop([feature_to_encode], axis=1)\n",
    "    return(res) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2420, 39)\n",
      "(2420,)\n",
      "[[ 0.3197384   0.64657353  1.11950795 ... -0.33790602  1.54268865\n",
      "  -0.32995601]\n",
      " [ 1.98801634  0.64657353 -0.71868204 ...  2.95940273 -0.64821894\n",
      "  -0.32995601]\n",
      " [-1.05413755 -0.24652461 -0.86008127 ... -0.33790602 -0.64821894\n",
      "  -0.32995601]\n",
      " ...\n",
      " [ 0.12347041 -0.24652461  0.83670949 ...  2.95940273 -0.64821894\n",
      "  -0.32995601]\n",
      " [-0.66160156 -1.13962275 -0.29448435 ... -0.33790602  1.54268865\n",
      "  -0.32995601]\n",
      " [-0.75973556 -0.24652461 -0.43588358 ... -0.33790602  1.54268865\n",
      "  -0.32995601]]\n"
     ]
    }
   ],
   "source": [
    "# Nominal: Gender, Marital Status, Dept, EmpType, CommuteMode\n",
    "# Ordinal: JobLevel, EduLevel\n",
    "data2 = data.copy()\n",
    "data2.drop(columns=['EmpID'], inplace=True)\n",
    "le = LabelEncoder() \n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# Ordinal\n",
    "EduLevel_map = {'High School':1, 'Bachelor':2, 'Master':3, 'PhD':4}\n",
    "JobLevel_map ={'Intern/Fresher':1, 'Junior':2, 'Mid':3, 'Senior':4, 'Lead':5}\n",
    "data2['EduLevel'] = data2['EduLevel'].replace(EduLevel_map)\n",
    "data2['JobLevel'] = data2['JobLevel'].replace(JobLevel_map)\n",
    "\n",
    "# Nominal\n",
    "Nominal = ['Gender', 'MaritalStatus', 'Dept', 'EmpType', 'CommuteMode']\n",
    "for feature in Nominal:\n",
    "    data2 = encode_and_bind(data2, feature)\n",
    "\n",
    "# Convert TrueFalse to int\n",
    "data2['haveOT'] = data2['haveOT'].astype(int)\n",
    "\n",
    "# Generate X and Y\n",
    "X = data2.drop(columns=['JobSatisfaction'])\n",
    "y = data2['JobSatisfaction']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xscaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xscaled, y, test_size=0.2)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train.toarray() if hasattr(X_train, \"toarray\") else X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.toarray() if hasattr(X_test, \"toarray\") else X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(39, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class NeuralNetworkClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(39, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 5)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 39])\n",
      "Shape of y: torch.Size([64, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_loader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from Pytorch Quickstart \n",
    "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, verbose=True):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        \n",
    "        loss = loss_fn(pred, y)\n",
    "        # pred_rounded = np.clip(np.round(pred), 1, 5)\n",
    "        # loss = loss_fn(pred_rounded, y).item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            if verbose:\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    total_loss/=len(dataloader)\n",
    "    if verbose:\n",
    "        print(f\"Total Loss: {total_loss:>7f}\")\n",
    "    return total_loss\n",
    "\n",
    "def test(dataloader, model, loss_fn, verbose=True):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            pred_rounded = np.clip(np.round(pred), 1, 5)\n",
    "\n",
    "            test_loss += loss_fn(pred_rounded, y).item()\n",
    "            correct += (pred_rounded == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    if verbose:\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\caleb\\miniconda3\\envs\\MSE446\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: round() received an invalid combination of arguments - got (decimals=int, out=NoneType, ), but expected one of:\n * ()\n * (*, int decimals)\n      didn't match because some of the keywords were incorrect: out\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m trainingLost \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# testingLoss, predictions, targets = test(test_loader, model, loss_fn)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m testingLoss, acc \u001b[38;5;241m=\u001b[39m test(test_loader, model, loss_fn, verbose)\n",
      "Cell \u001b[1;32mIn[102], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer, verbose)\u001b[0m\n\u001b[0;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m---> 16\u001b[0m pred_rounded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# loss = loss_fn(pred_rounded, y).item()\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mround_\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\caleb\\miniconda3\\envs\\MSE446\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3763\u001b[0m, in \u001b[0;36mround_\u001b[1;34m(a, decimals, out)\u001b[0m\n\u001b[0;32m   3754\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_around_dispatcher)\n\u001b[0;32m   3755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mround_\u001b[39m(a, decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3756\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3757\u001b[0m \u001b[38;5;124;03m    Round an array to the given number of decimals.\u001b[39;00m\n\u001b[0;32m   3758\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3761\u001b[0m \u001b[38;5;124;03m    around : equivalent function; see for details.\u001b[39;00m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3763\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maround\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecimals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36maround\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\caleb\\miniconda3\\envs\\MSE446\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3337\u001b[0m, in \u001b[0;36maround\u001b[1;34m(a, decimals, out)\u001b[0m\n\u001b[0;32m   3245\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_around_dispatcher)\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maround\u001b[39m(a, decimals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3247\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3248\u001b[0m \u001b[38;5;124;03m    Evenly round to the given number of decimals.\u001b[39;00m\n\u001b[0;32m   3249\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3335\u001b[0m \n\u001b[0;32m   3336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mround\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecimals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caleb\\miniconda3\\envs\\MSE446\\lib\\site-packages\\numpy\\core\\fromnumeric.py:66\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caleb\\miniconda3\\envs\\MSE446\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m, method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[1;32mc:\\Users\\caleb\\miniconda3\\envs\\MSE446\\lib\\site-packages\\torch\\_tensor.py:1083\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# Setting up problem\n",
    "model = NeuralNetwork()\n",
    "# print(model)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "trainLoss = []\n",
    "testLoss = []\n",
    "accuracy = []\n",
    "# Training Loop\n",
    "epochs = 300\n",
    "verbose = False\n",
    "for t in range(epochs):\n",
    "    if verbose:\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    trainingLost = train(train_loader, model, loss_fn, optimizer, verbose)\n",
    "    # testingLoss, predictions, targets = test(test_loader, model, loss_fn)\n",
    "    testingLoss, acc = test(test_loader, model, loss_fn, verbose)\n",
    "\n",
    "    trainLoss.append(trainingLost)\n",
    "    testLoss.append(testingLoss)\n",
    "    accuracy.append(acc)\n",
    "\n",
    "print(\"Done!\")\n",
    "print(accuracy[-1])\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(trainLoss, label=\"train\")\n",
    "plt.plot(testLoss, label=\"test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(accuracy, label=\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNetwork()\n",
    "# model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSE446",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
